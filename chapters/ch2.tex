\chapter{TRADITIONAL INPAINTING METHODS}\label{traditional_methods}

There are many different methods used for image inpainting. Each of these methods has mathematical foundations in itself. These methods are categorized according to the algorithms they use to get the desired output\cite{exemplerinpainting}. The first of these methods are the methods called traditional methods that try to correct the missing part on the main title picture only with the features in the picture to be corrected.

Machine learning methods, which have been used frequently in many different problems due to increased processing power and broad access to large data sets, have also started to be used for image inpainting problems. These ideas, which will be explained under the title of traditional methods, also formed the basis for machine learning and deep learning methods used for inpainting. The methods explained under this title were used in different deep learning methods, which will be examined later.

It would be more accurate to examine traditional methods mainly as exemplar-based and diffusion-based. Although Exemplar-based methods are divided into pixel-based and patch-based, patch-based methods will be examined mainly in exemplar-based methods, since there are more studies relating to patch-based methods and they give better results. \cite{trad1} and \cite{trad2} are some of the traditional method example works.

As can be understood from their names, patch-based methods try to fill the missing region in the picture with the information obtained from different parts of the picture. Diffusion-based methods try to fill the region by diffusing surrounding pixels from its boundary \cite{navier_stokes_inpainting}, \cite{telea}.

Traditional methods are methods that do not require training. For this reason, it is an appropriate method to use for simpler problems. Traditional methods do not work well in problems where the masked area in the picture starts to form a proportionally large area. This result is quite normal given that these methods infer from pixels near the missing region.

\section{Patch-based Methods}

Patch-based image inpainting consists of methods that use the undamaged regions in the image to create the region to be filled. With this approach, it is aimed to have the highest possible patch similarity level\cite{inpaintingoverview}.

In order to implement this method, an algorithm is needed on how to transfer the obtained regions to the areas planned to be filled. Another important point in this method is the selection of the algorithm that will compare the regions in different parts of the picture with the regions desired to be created \cite{patchmatch}.

While patch-based methods work well, they assume that the information in the missing part of the picture resides elsewhere in the picture. Another problem with patch-based methods is that they require relatively more processing power because they are methods that consistently involve searching and comparing.

\subsection{Patch-based Texture Synthesis}

In this method by Zhou et al. \cite{patch_based_tex_synthesis}, it is aimed to fill the desired area by creating textures with patch-based algorithms for Image inpainting method. While implementing this targeted method, a road starting from the rough, proceeding in detail is aimed. While performing the filling process, targets and constraints were created in order to ensure the integrity of the newly created region with the rest of the picture.

In this study, a more efficient inpainting study has been achieved by basically using the successive elimination algorithm and based on the previously used methods.

Texture synthesis is performed by trying to imitate information about texture and structure integrity. At the same time, it is aimed to reduce the processing power used by using the successive elimination algorithm during texture comparison.

In this approach, the function given in equation \ref{eqn:textsynth} is tried to be minimized in order to achieve the desired result.

\begin{equation}
    \label{eqn:textsynth}
    I_t = \frac{1}{k_p} \displaystyle\sum\limits_{q\epsilon\Omega} {I_qf(|p-q|).g(|I_p-I_q|)}
\end{equation}

However, minimizing this equation does not mean that the energy function decreases in general. To explain better, the region to be filled in the image can be completely filled with a smaller patch than itself and gives a perfect result in the equation. However, for better results, coarse images as  are used in equation \ref{eqn:textsynth2} and equation \ref{eqn:textsynth3}.

\begin{equation}
    \label{eqn:textsynth2}
    \lambda(x,y)(\mu_1-\mu_0)=\mu\Delta^2\mu1, where \frac{\partial\mu_1}{\partial n}
\end{equation}

\begin{equation}
    \label{eqn:textsynth3}
    \lambda(x,y)(\mu_2-\mu_0)=\mu\Delta^2\mu2, where \frac{\partial\mu_2}{\partial n}
\end{equation}

In this way, the image inpainting process for the visual is corrected to give a good result from the rough approach. However, this process requires a high processing power due to 3 different partial differential equations.

\begin{equation}
    \label{eqn:textsynth4}
    E(c_k, C) = \sum\limits_{k}\int\limits_{\Omega_k}\lambda(x,y){(c_k,\mu_0)}^2dxy+V|C|
\end{equation}

It is logical to use an approach to solve this problem. With this approach, uniform visual densities can be accepted as constant for different regions. Hence, MS energy function can be reduced to equation \ref{eqn:textsynth4}. Also, an inpainted image example with its input image is given in figure \ref{fig:patch-based-example}.

\begin{figure}[h]
    \centering
    \includegraphics{figures/chapter2/Patch-Based-texture-synth-example.png}
    \vspace*{5mm}
    \caption{Inpainted Image with Patch Based Texture Synthesis\cite{patch_based_tex_synthesis}}
    \label{fig:patch-based-example}
\end{figure}

\subsection{Image Melding}

The image melting method \cite{imagemelding} creates a transition zone to transfer various information and properties within one image to another image. This method can be used for different purposes depending on the usage type.

This method, primarily uses many different transforms to increase the ability to search for patches. Next, image gradients are included in patch representation and Poisson equation solver is used for color averaging. Without causing blurry areas in the picture, a new energy method is used based on \(L_2/L_0\) norms for colors. Melding of 2 different image is illustrated below in figure \ref{fig:image-melding-example}.

\begin{figure}[h]
    \centering
    \includegraphics{figures/chapter2/Image-Melding.png}
    \vspace*{5mm}
    \caption{Image Melding Example \cite{imagemelding}}
    \label{fig:image-melding-example}
\end{figure}

Many different patch-based methods have been used for inpainting problems. Image melding is basically a patch-based algorithm. However, when based-patched methods are given inconsistent visuals, they can give insufficient results because they use a direct distance function between pixels.

Another result aimed with this study is that patch-based and gradient methods can be used together and thus more complex problems can be solved. Thanks to the methods used, Image Melding can be used to solve many different problems including inpainting.

Image synthesis using a single source is one of the ways image melding can be used. In this algorithm, a mask divides the image into two parts, S and T, respectively, as source and target. After this process, the energy function shown in equation \ref{eqn:imagemelding1} is obtained.

\begin{equation}
    \label{eqn:imagemelding1}
    E(T,S) = \sum\limits_{q\subset T}{min_{p\subset S}(D(Q,P)+\lambda D(\Delta Q, \Delta P))}
\end{equation}

In the above equation Q represents the targeted patch with w width and height and target pixel q on the upper left corner. P represents the transformation that is applied to the neighbor pixels of the source pixel. Throughout the operations, all patches have 5 channels, which 3 of them are RGB and 2 channels are gradient channels. In the equation \ref{eqn:imagemelding1}, RGB channels are shown with Q and P, gradient channels are shown with \(\Delta Q \Delta P \)Distances for all channels are expressed with D and,  weight the gradient channels in according to RGB channels.

Two important steps during the implementation of the algorithm are searching and voting. For the search part, the PatchMatch algorithm is properly used. With using this algorithm, patches with sufficient proximity are detected for the target patch. Translation, rotation and scaling are used freely during this process. At the same time, ranges are defined on the channels in order to obtain better results.

\begin{equation}
    \label{eqn:imagemelding2}
    T= argmin(D(I,\bar{T}+\lambda D(\Delta I,\Delta \bar{T}))
    %sYanlislik olabilir mi kontrol et bir ara
\end{equation}

In the voting part, an algorithm is used in which every pixel in the patch is included, and the resulting output takes its form in eq \ref{eqn:imagemelding2}. In figure \ref{fig:inpainting-image-melding}, Inpainting example with image melding method is given.

\begin{figure}[h]
    \centering
    \includegraphics{figures/chapter2/ImageMeldingExample.png}
    \vspace*{5mm}
    \caption{Inpaingting Example with Image Melding\cite{imagemelding}}
    \label{fig:inpainting-image-melding}
\end{figure}

\section{Diffusion-based Methods}

This method basically fills missing regions or unwanted objects in an image by diffusing neighboring pixel information. Diffusion process uses partial differential equations. Inpainting is not the only use of such diffusion-based methods. In addition, these type of methods are available in areas like image compression. Diffusion-based image inpainting can be used to remove undesirable objects in an image or to repair damaged parts of it. However, as a downside, these methods can leave artifacts after inpainting process such as local variance difference and noise pattern \cite{diffusion_based_artifacts}. In figure \ref{fig:diffusion_based_inpainting} an example of diffusion-based inpainting can be seen. The black region in \ref{fig:diffusion_based_inpainting}.a is the unknown region and the \ref{fig:diffusion_based_inpainting}.b shows the inpainting result, the region surrounded by the dashed curve is recovered by inpainting.

Basically, the inpainting process is nothing more than restoring the missing pixel information in an image and there are some common assumptions that most of the images have commonly share. In this way of thinking, Navier-Stokes based method \cite{navier_stokes} was introduced. Navier-Stokes equations known in the area of mechanics, especially fluid mechanics. This inpainting method emerged by combining ideas in the field of classical fluid dynamics with the help of partial equations and remains one of the most popular traditional methods to this day. The assumption that the edges in an image are continuous is used. The authors designed this inpainting method by considering the color information of the surrounding pixels and the this continuity constraint.

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{figures/chapter2/diffusion_based_inpainting.png}
    \caption{Diffusion-based inpainting example \cite{diffusion_based_inpainting}}
    \label{fig:diffusion_based_inpainting}
\end{figure}

Another traditional inpainting study based on fast marching method \cite{telea} proposed that, in order to estimate the color of the missing pixels, gradients of the neighbor regions can be used. In our work, these two methods used as a baseline when comparing the deep learning based inpainting methods with traditional inpainting methods.

\subsection{Navier-Stokes Method}

Navier-Strokes equations are partial differential equations for describing the motion of fluid substances. These equations used in variety of areas in different industries such as modeling ocean currents, weather conditions and even when designing aircrafts and cars.

\begin{equation}
    \omega_{t} + \upsilon \cdot \nabla \omega = \nu \nabla \cdot \left ( g \left ( \left | \nabla \omega \right | \right ) \nabla \omega \right)
    \label{eq:navier_stokes}
\end{equation}

In this method \cite{navier_stokes}, the stream function formulation used in fluid mechanics has been made suitable for the inpainting process. The counterpart to the vorticity-stream function for inpainting transform into equation \ref{eq:navier_stokes} which corresponds to the solution of the intensity value of a pixel. \cite{navier_stokes_inpainting} Similarly, the fluid velocity in fluid dynamics corresponds to the gradient of the intensity values also interpereted as isophote direction, vortocity corresponds to smoothness and viscosity corresponds to diffusion respectively in this problem.

The algorithm used in this study proceeds by following the edges in the picture from the known region to the unknown region. Since it is assumed that the edges will be continous during this progress, isophote lines are preserved. Isophote means the lines created by pixels with the same intensity value. During this process, the direction of the gradient vector in the boundaries preserved. After the isophotes are obtained, color information is calculated to reduce the minimum variance and by filling in the unknown pixels, the inpainting process is completed.

\subsection{Fast Marching Method}

In this study published in 2004 \cite{telea}, Ahmet developed an inpainting technique based on the fast marching method. A filling process is designed starting from the boundary pixels of a region where the pixel information is missing and going step by step towards the inside. It takes a small neighborhood of pixels to calculate the unknown pixel value as the weighted sum of known pixels inside that boundary. For this weighted summation process, the weights selected according to the proximity and boundary normal. After all the pixels are calculated in each step, the next closest pixel is passed with the fast marching method and the same process is repeated again until everything inside the region is inpainted. FMM ensures that the pixels which are near to the known pixels inpainted first and inside pixels will be filled afterwards. This inpainting priciple can be seen in figure \ref{fig:ffm}. Pixel \(p\) in figure \ref{fig:ffm}.a will be inpainted. Inside a small region \(\epsilon\), for any \(q\) known pixel, the gradient \(\nabla I\) will be calculated as seen in figure \ref{fig:ffm}.b.  

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{figures/chapter2/ffm.png}
    \vspace*{4mm}
    \caption{Fast marching method inpainting priciple}
    \label{fig:ffm}
\end{figure}

In figure \ref{fig:traditional_comparison}, comparison of the Navier-Stokes and Fast Marching approaches can bee seen. White colored pixels in \ref{fig:traditional_comparison}.a are the missing areas and \ref{fig:traditional_comparison}.d is the original image. In \ref{fig:traditional_comparison}.b, output of the Navier-Stokes method and in \ref{fig:traditional_comparison}.c, output of the Fast Marching method shown respectively.

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{figures/chapter2/traditional_comparison.png}
    \caption{Comparison of Navier-Stokes and Fast Marching methods}
    \label{fig:traditional_comparison}
\end{figure}
